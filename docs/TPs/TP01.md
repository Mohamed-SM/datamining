### DataSet : Glass


**Le nombre d'attributs** : 10

**Le nombre d'instances** : 214

#### Résumé de dataset

```Summary 
Relation Name:  Glass
Num Instances:  214
Num Attributes: 10

     Name                      Type  Nom  Int Real     Missing      Unique  Dist
 1 RI                         Num   0%   0% 100%     0 /  0%   145 / 68%   178 
 2 Na                         Num   0%   3%  97%     0 /  0%    97 / 45%   142 
 3 Mg                         Num   0%  20%  80%     0 /  0%    62 / 29%    94 
 4 Al                         Num   0%   1%  99%     0 /  0%    64 / 30%   118 
 5 Si                         Num   0%   1%  99%     0 /  0%    78 / 36%   133 
 6 K                          Num   0%  14%  86%     0 /  0%    30 / 14%    65 
 7 Ca                         Num   0%   1%  99%     0 /  0%    95 / 44%   143 
 8 Ba                         Num   0%  82%  18%     0 /  0%    28 / 13%    34 
 9 Fe                         Num   0%  67%  33%     0 /  0%    17 /  8%    32 
10 Type                       Nom 100%   0%   0%     0 /  0%     0 /  0%     6 
```



#### Algo: OneR

**Results** :

|  | Precision | Recall | F-Measure |
| --- | --- | --- | --- |
| Training set : | NaN | 0.631 | NaN | 
| Cross-validation (10) : | NaN | 0.579 | NaN | 
| Leave one out (214) : | NaN | 0.579 | NaN | 
| Hold out (70%) : | NaN | 0.547 | NaN | 
**Comparaison** :

comparaison à l'aide du **F-Measure** :

le meilleur résultat est :  
la valeur qu'il a donné : 0.000

comparaison à l'aide du **Recall** :

le meilleur résultat est : Cross validation (10) 
la valeur qu'il a donné : 0.579

comparaison à l'aide du **Precision** :

le meilleur résultat est  
la valeur qu'il a donné : 0.000



#### Algo: NaiveBayes

**Results** :

|  | Precision | Recall | F-Measure |
| --- | --- | --- | --- |
| Training set : | 0.564 | 0.556 | 0.506 | 
| Cross-validation (10) : | 0.491 | 0.477 | 0.447 | 
| Leave one out (214) : | 0.483 | 0.495 | 0.448 | 
| Hold out (70%) : | 0.509 | 0.438 | 0.410 | 
**Comparaison** :

comparaison à l'aide du **F-Measure** :

le meilleur résultat est : Leave one out (214) 
la valeur qu'il a donné : 0.509

comparaison à l'aide du **Recall** :

le meilleur résultat est : Leave one out (214) 
la valeur qu'il a donné : 0.495

comparaison à l'aide du **Precision** :

le meilleur résultat est Hold out (70%) 
la valeur qu'il a donné : 0.448



#### Algo: IBk

**Results** :

|  | Precision | Recall | F-Measure |
| --- | --- | --- | --- |
| Training set : | 1.000 | 1.000 | 1.000 | 
| Cross-validation (10) : | 0.706 | 0.706 | 0.705 | 
| Leave one out (214) : | 0.704 | 0.701 | 0.701 | 
| Hold out (70%) : | 0.706 | 0.688 | 0.693 | 
**Comparaison** :

comparaison à l'aide du **F-Measure** :

le meilleur résultat est : Cross validation (10) 
la valeur qu'il a donné : 0.706

comparaison à l'aide du **Recall** :

le meilleur résultat est : Cross validation (10) 
la valeur qu'il a donné : 0.706

comparaison à l'aide du **Precision** :

le meilleur résultat est Hold out (70%) 
la valeur qu'il a donné : 0.705



#### Algo: J48

**Results** :

|  | Precision | Recall | F-Measure |
| --- | --- | --- | --- |
| Training set : | 0.963 | 0.963 | 0.962 | 
| Cross-validation (10) : | 0.655 | 0.668 | 0.660 | 
| Leave one out (214) : | 0.671 | 0.668 | 0.668 | 
| Hold out (70%) : | 0.725 | 0.719 | 0.714 | 
**Comparaison** :

comparaison à l'aide du **F-Measure** :

le meilleur résultat est : Hold out (70%) 
la valeur qu'il a donné : 0.725

comparaison à l'aide du **Recall** :

le meilleur résultat est : Hold out (70%) 
la valeur qu'il a donné : 0.719

comparaison à l'aide du **Precision** :

le meilleur résultat est Hold out (70%) 
la valeur qu'il a donné : 0.714



#### Algo: Id3

Une **erreur** s'est produite lors de l'évaluation

!>weka.classifiers.trees.Id3: Cannot handle numeric attributes!

#### Comparaison entre algorithmes :

comparaison à l'aide du **F-Measure** :

le meilleur algorithme est : **J48** 

le meilleur résultat est : Hold out (70%) 
la valeur qu'il a donné : 0.725


comparaison à l'aide du **Recall** :

le meilleur algorithme est : **J48** 

le meilleur résultat est : Hold out (70%) 
la valeur qu'il a donné : 0.719


comparaison à l'aide du **Precision** :

le meilleur algorithme est : **J48** 

le meilleur résultat est Hold out (70%) 
la valeur qu'il a donné : 0.714


### DataSet : breast-cancer


**Le nombre d'attributs** : 10

**Le nombre d'instances** : 286

#### Résumé de dataset

```Summary 
Relation Name:  breast-cancer
Num Instances:  286
Num Attributes: 10

     Name                      Type  Nom  Int Real     Missing      Unique  Dist
 1 age                        Nom 100%   0%   0%     0 /  0%     1 /  0%     6 
 2 menopause                  Nom 100%   0%   0%     0 /  0%     0 /  0%     3 
 3 tumor-size                 Nom 100%   0%   0%     0 /  0%     0 /  0%    11 
 4 inv-nodes                  Nom 100%   0%   0%     0 /  0%     1 /  0%     7 
 5 node-caps                  Nom  97%   0%   0%     8 /  3%     0 /  0%     2 
 6 deg-malig                  Nom 100%   0%   0%     0 /  0%     0 /  0%     3 
 7 breast                     Nom 100%   0%   0%     0 /  0%     0 /  0%     2 
 8 breast-quad                Nom 100%   0%   0%     1 /  0%     0 /  0%     5 
 9 irradiat                   Nom 100%   0%   0%     0 /  0%     0 /  0%     2 
10 Class                      Nom 100%   0%   0%     0 /  0%     0 /  0%     2 
```



#### Algo: OneR

**Results** :

|  | Precision | Recall | F-Measure |
| --- | --- | --- | --- |
| Training set : | 0.703 | 0.727 | 0.680 | 
| Cross-validation (10) : | 0.624 | 0.657 | 0.635 | 
| Leave one out (286) : | 0.666 | 0.706 | 0.655 | 
| Hold out (70%) : | 0.614 | 0.640 | 0.599 | 
**Comparaison** :

comparaison à l'aide du **F-Measure** :

le meilleur résultat est : Leave one out (286) 
la valeur qu'il a donné : 0.666

comparaison à l'aide du **Recall** :

le meilleur résultat est : Leave one out (286) 
la valeur qu'il a donné : 0.706

comparaison à l'aide du **Precision** :

le meilleur résultat est Leave one out (286) 
la valeur qu'il a donné : 0.655



#### Algo: NaiveBayes

**Results** :

|  | Precision | Recall | F-Measure |
| --- | --- | --- | --- |
| Training set : | 0.740 | 0.752 | 0.743 | 
| Cross-validation (10) : | 0.714 | 0.727 | 0.718 | 
| Leave one out (286) : | 0.712 | 0.727 | 0.716 | 
| Hold out (70%) : | 0.768 | 0.756 | 0.761 | 
**Comparaison** :

comparaison à l'aide du **F-Measure** :

le meilleur résultat est : Hold out (70%) 
la valeur qu'il a donné : 0.768

comparaison à l'aide du **Recall** :

le meilleur résultat est : Hold out (70%) 
la valeur qu'il a donné : 0.756

comparaison à l'aide du **Precision** :

le meilleur résultat est Hold out (70%) 
la valeur qu'il a donné : 0.761



#### Algo: IBk

**Results** :

|  | Precision | Recall | F-Measure |
| --- | --- | --- | --- |
| Training set : | 0.979 | 0.979 | 0.979 | 
| Cross-validation (10) : | 0.697 | 0.720 | 0.698 | 
| Leave one out (286) : | 0.713 | 0.734 | 0.711 | 
| Hold out (70%) : | 0.727 | 0.733 | 0.716 | 
**Comparaison** :

comparaison à l'aide du **F-Measure** :

le meilleur résultat est : Hold out (70%) 
la valeur qu'il a donné : 0.727

comparaison à l'aide du **Recall** :

le meilleur résultat est : Leave one out (286) 
la valeur qu'il a donné : 0.734

comparaison à l'aide du **Precision** :

le meilleur résultat est Hold out (70%) 
la valeur qu'il a donné : 0.716



#### Algo: J48

**Results** :

|  | Precision | Recall | F-Measure |
| --- | --- | --- | --- |
| Training set : | 0.760 | 0.759 | 0.716 | 
| Cross-validation (10) : | 0.709 | 0.731 | 0.685 | 
| Leave one out (286) : | 0.752 | 0.755 | 0.713 | 
| Hold out (70%) : | 0.666 | 0.709 | 0.675 | 
**Comparaison** :

comparaison à l'aide du **F-Measure** :

le meilleur résultat est : Leave one out (286) 
la valeur qu'il a donné : 0.752

comparaison à l'aide du **Recall** :

le meilleur résultat est : Leave one out (286) 
la valeur qu'il a donné : 0.755

comparaison à l'aide du **Precision** :

le meilleur résultat est Leave one out (286) 
la valeur qu'il a donné : 0.713



#### Algo: Id3

Une **erreur** s'est produite lors de l'évaluation

!>weka.classifiers.trees.Id3: Cannot handle missing values!

#### Comparaison entre algorithmes :

comparaison à l'aide du **F-Measure** :

le meilleur algorithme est : **NaiveBayes** 

le meilleur résultat est : Hold out (70%) 
la valeur qu'il a donné : 0.768


comparaison à l'aide du **Recall** :

le meilleur algorithme est : **NaiveBayes** 

le meilleur résultat est : Hold out (70%) 
la valeur qu'il a donné : 0.756


comparaison à l'aide du **Precision** :

le meilleur algorithme est : **NaiveBayes** 

le meilleur résultat est Hold out (70%) 
la valeur qu'il a donné : 0.761


### DataSet : contact-lenses


**Le nombre d'attributs** : 5

**Le nombre d'instances** : 24

#### Résumé de dataset

```Summary 
Relation Name:  contact-lenses
Num Instances:  24
Num Attributes: 5

     Name                      Type  Nom  Int Real     Missing      Unique  Dist
1 age                        Nom 100%   0%   0%     0 /  0%     0 /  0%     3 
2 spectacle-prescrip         Nom 100%   0%   0%     0 /  0%     0 /  0%     2 
3 astigmatism                Nom 100%   0%   0%     0 /  0%     0 /  0%     2 
4 tear-prod-rate             Nom 100%   0%   0%     0 /  0%     0 /  0%     2 
5 contact-lenses             Nom 100%   0%   0%     0 /  0%     0 /  0%     3 
```



#### Algo: OneR

**Results** :

|  | Precision | Recall | F-Measure |
| --- | --- | --- | --- |
| Training set : | NaN | 0.708 | NaN | 
| Cross-validation (10) : | NaN | 0.708 | NaN | 
| Leave one out (24) : | NaN | 0.708 | NaN | 
| Hold out (70%) : | NaN | 0.286 | NaN | 
**Comparaison** :

comparaison à l'aide du **F-Measure** :

le meilleur résultat est :  
la valeur qu'il a donné : 0.000

comparaison à l'aide du **Recall** :

le meilleur résultat est : Cross validation (10) 
la valeur qu'il a donné : 0.708

comparaison à l'aide du **Precision** :

le meilleur résultat est  
la valeur qu'il a donné : 0.000



#### Algo: NaiveBayes

**Results** :

|  | Precision | Recall | F-Measure |
| --- | --- | --- | --- |
| Training set : | 0.965 | 0.958 | 0.960 | 
| Cross-validation (10) : | 0.691 | 0.708 | 0.698 | 
| Leave one out (24) : | 0.691 | 0.708 | 0.698 | 
| Hold out (70%) : | 0.786 | 0.714 | 0.714 | 
**Comparaison** :

comparaison à l'aide du **F-Measure** :

le meilleur résultat est : Hold out (70%) 
la valeur qu'il a donné : 0.786

comparaison à l'aide du **Recall** :

le meilleur résultat est : Hold out (70%) 
la valeur qu'il a donné : 0.714

comparaison à l'aide du **Precision** :

le meilleur résultat est Hold out (70%) 
la valeur qu'il a donné : 0.714



#### Algo: IBk

**Results** :

|  | Precision | Recall | F-Measure |
| --- | --- | --- | --- |
| Training set : | 1.000 | 1.000 | 1.000 | 
| Cross-validation (10) : | 0.750 | 0.750 | 0.750 | 
| Leave one out (24) : | 0.750 | 0.750 | 0.750 | 
| Hold out (70%) : | 0.886 | 0.857 | 0.841 | 
**Comparaison** :

comparaison à l'aide du **F-Measure** :

le meilleur résultat est : Hold out (70%) 
la valeur qu'il a donné : 0.886

comparaison à l'aide du **Recall** :

le meilleur résultat est : Hold out (70%) 
la valeur qu'il a donné : 0.857

comparaison à l'aide du **Precision** :

le meilleur résultat est Hold out (70%) 
la valeur qu'il a donné : 0.841



#### Algo: J48

**Results** :

|  | Precision | Recall | F-Measure |
| --- | --- | --- | --- |
| Training set : | 0.924 | 0.917 | 0.916 | 
| Cross-validation (10) : | 0.851 | 0.833 | 0.836 | 
| Leave one out (24) : | 0.851 | 0.833 | 0.836 | 
| Hold out (70%) : | 1.000 | 1.000 | 1.000 | 
**Comparaison** :

comparaison à l'aide du **F-Measure** :

le meilleur résultat est : Hold out (70%) 
la valeur qu'il a donné : 1.000

comparaison à l'aide du **Recall** :

le meilleur résultat est : Hold out (70%) 
la valeur qu'il a donné : 1.000

comparaison à l'aide du **Precision** :

le meilleur résultat est Hold out (70%) 
la valeur qu'il a donné : 1.000



#### Algo: Id3

**Results** :

|  | Precision | Recall | F-Measure |
| --- | --- | --- | --- |
| Training set : | 1.000 | 1.000 | 1.000 | 
| Cross-validation (10) : | 0.691 | 0.708 | 0.698 | 
| Leave one out (24) : | 0.691 | 0.708 | 0.698 | 
| Hold out (70%) : | 1.000 | 0.800 | 0.889 | 
**Comparaison** :

comparaison à l'aide du **F-Measure** :

le meilleur résultat est : Hold out (70%) 
la valeur qu'il a donné : 1.000

comparaison à l'aide du **Recall** :

le meilleur résultat est : Hold out (70%) 
la valeur qu'il a donné : 0.800

comparaison à l'aide du **Precision** :

le meilleur résultat est Hold out (70%) 
la valeur qu'il a donné : 0.889

#### Comparaison entre algorithmes :

comparaison à l'aide du **F-Measure** :

le meilleur algorithme est : **J48** 

le meilleur résultat est : Hold out (70%) 
la valeur qu'il a donné : 1.000


comparaison à l'aide du **Recall** :

le meilleur algorithme est : **J48** 

le meilleur résultat est : Hold out (70%) 
la valeur qu'il a donné : 1.000


comparaison à l'aide du **Precision** :

le meilleur algorithme est : **J48** 

le meilleur résultat est Hold out (70%) 
la valeur qu'il a donné : 1.000


### DataSet : cpu


**Le nombre d'attributs** : 7

**Le nombre d'instances** : 209

#### Résumé de dataset

```Summary 
Relation Name:  cpu
Num Instances:  209
Num Attributes: 7

     Name                      Type  Nom  Int Real     Missing      Unique  Dist
1 MYCT                       Num   0% 100%   0%     0 /  0%    19 /  9%    60 
2 MMIN                       Num   0% 100%   0%     0 /  0%    11 /  5%    25 
3 MMAX                       Num   0% 100%   0%     0 /  0%     6 /  3%    23 
4 CACH                       Num   0% 100%   0%     0 /  0%     4 /  2%    22 
5 CHMIN                      Num   0% 100%   0%     0 /  0%     4 /  2%    15 
6 CHMAX                      Num   0% 100%   0%     0 /  0%     9 /  4%    31 
7 class                      Num   0% 100%   0%     0 /  0%    72 / 34%   116 
```



#### Algo: OneR

Une **erreur** s'est produite lors de l'évaluation

!>weka.classifiers.rules.OneR: Cannot handle numeric class!



#### Algo: NaiveBayes

Une **erreur** s'est produite lors de l'évaluation

!>weka.classifiers.bayes.NaiveBayes: Cannot handle numeric class!



#### Algo: IBk

Une **erreur** s'est produite lors de l'évaluation

!>null



#### Algo: J48

Une **erreur** s'est produite lors de l'évaluation

!>weka.classifiers.trees.J48: Cannot handle numeric class!



#### Algo: Id3

Une **erreur** s'est produite lors de l'évaluation

!>weka.classifiers.trees.Id3: Cannot handle numeric attributes!

#### Comparaison entre algorithmes :

comparaison à l'aide du **F-Measure** :

le meilleur algorithme est : **** 

le meilleur résultat est :  
la valeur qu'il a donné : 0.000


comparaison à l'aide du **Recall** :

le meilleur algorithme est : **** 

le meilleur résultat est :  
la valeur qu'il a donné : 0.000


comparaison à l'aide du **Precision** :

le meilleur algorithme est : **** 

le meilleur résultat est  
la valeur qu'il a donné : 0.000


### DataSet : iris


**Le nombre d'attributs** : 5

**Le nombre d'instances** : 150

#### Résumé de dataset

```Summary 
Relation Name:  iris
Num Instances:  150
Num Attributes: 5

     Name                      Type  Nom  Int Real     Missing      Unique  Dist
1 sepallength                Num   0%  11%  89%     0 /  0%     9 /  6%    35 
2 sepalwidth                 Num   0%  19%  81%     0 /  0%     5 /  3%    23 
3 petallength                Num   0%   9%  91%     0 /  0%    10 /  7%    43 
4 petalwidth                 Num   0%   9%  91%     0 /  0%     2 /  1%    22 
5 class                      Nom 100%   0%   0%     0 /  0%     0 /  0%     3 
```



#### Algo: OneR

**Results** :

|  | Precision | Recall | F-Measure |
| --- | --- | --- | --- |
| Training set : | 0.962 | 0.960 | 0.960 | 
| Cross-validation (10) : | 0.920 | 0.920 | 0.920 | 
| Leave one out (150) : | 0.913 | 0.913 | 0.913 | 
| Hold out (70%) : | 0.960 | 0.956 | 0.955 | 
**Comparaison** :

comparaison à l'aide du **F-Measure** :

le meilleur résultat est : Hold out (70%) 
la valeur qu'il a donné : 0.960

comparaison à l'aide du **Recall** :

le meilleur résultat est : Hold out (70%) 
la valeur qu'il a donné : 0.956

comparaison à l'aide du **Precision** :

le meilleur résultat est Hold out (70%) 
la valeur qu'il a donné : 0.955



#### Algo: NaiveBayes

**Results** :

|  | Precision | Recall | F-Measure |
| --- | --- | --- | --- |
| Training set : | 0.960 | 0.960 | 0.960 | 
| Cross-validation (10) : | 0.960 | 0.960 | 0.960 | 
| Leave one out (150) : | 0.953 | 0.953 | 0.953 | 
| Hold out (70%) : | 0.979 | 0.978 | 0.978 | 
**Comparaison** :

comparaison à l'aide du **F-Measure** :

le meilleur résultat est : Hold out (70%) 
la valeur qu'il a donné : 0.979

comparaison à l'aide du **Recall** :

le meilleur résultat est : Hold out (70%) 
la valeur qu'il a donné : 0.978

comparaison à l'aide du **Precision** :

le meilleur résultat est Hold out (70%) 
la valeur qu'il a donné : 0.978



#### Algo: IBk

**Results** :

|  | Precision | Recall | F-Measure |
| --- | --- | --- | --- |
| Training set : | 1.000 | 1.000 | 1.000 | 
| Cross-validation (10) : | 0.953 | 0.953 | 0.953 | 
| Leave one out (150) : | 0.953 | 0.953 | 0.953 | 
| Hold out (70%) : | 0.956 | 0.956 | 0.956 | 
**Comparaison** :

comparaison à l'aide du **F-Measure** :

le meilleur résultat est : Hold out (70%) 
la valeur qu'il a donné : 0.956

comparaison à l'aide du **Recall** :

le meilleur résultat est : Hold out (70%) 
la valeur qu'il a donné : 0.956

comparaison à l'aide du **Precision** :

le meilleur résultat est Hold out (70%) 
la valeur qu'il a donné : 0.956



#### Algo: J48

**Results** :

|  | Precision | Recall | F-Measure |
| --- | --- | --- | --- |
| Training set : | 0.980 | 0.980 | 0.980 | 
| Cross-validation (10) : | 0.947 | 0.947 | 0.947 | 
| Leave one out (150) : | 0.954 | 0.953 | 0.954 | 
| Hold out (70%) : | 0.892 | 0.844 | 0.845 | 
**Comparaison** :

comparaison à l'aide du **F-Measure** :

le meilleur résultat est : Leave one out (150) 
la valeur qu'il a donné : 0.954

comparaison à l'aide du **Recall** :

le meilleur résultat est : Leave one out (150) 
la valeur qu'il a donné : 0.953

comparaison à l'aide du **Precision** :

le meilleur résultat est Leave one out (150) 
la valeur qu'il a donné : 0.954



#### Algo: Id3

Une **erreur** s'est produite lors de l'évaluation

!>weka.classifiers.trees.Id3: Cannot handle numeric attributes!

#### Comparaison entre algorithmes :

comparaison à l'aide du **F-Measure** :

le meilleur algorithme est : **NaiveBayes** 

le meilleur résultat est : Hold out (70%) 
la valeur qu'il a donné : 0.979


comparaison à l'aide du **Recall** :

le meilleur algorithme est : **NaiveBayes** 

le meilleur résultat est : Hold out (70%) 
la valeur qu'il a donné : 0.978


comparaison à l'aide du **Precision** :

le meilleur algorithme est : **NaiveBayes** 

le meilleur résultat est Hold out (70%) 
la valeur qu'il a donné : 0.978


### DataSet : vote


**Le nombre d'attributs** : 17

**Le nombre d'instances** : 435

#### Résumé de dataset

```Summary 
Relation Name:  vote
Num Instances:  435
Num Attributes: 17

     Name                      Type  Nom  Int Real     Missing      Unique  Dist
 1 handicapped-infants        Nom  97%   0%   0%    12 /  3%     0 /  0%     2 
 2 water-project-cost-sharin  Nom  89%   0%   0%    48 / 11%     0 /  0%     2 
 3 adoption-of-the-budget-re  Nom  97%   0%   0%    11 /  3%     0 /  0%     2 
 4 physician-fee-freeze       Nom  97%   0%   0%    11 /  3%     0 /  0%     2 
 5 el-salvador-aid            Nom  97%   0%   0%    15 /  3%     0 /  0%     2 
 6 religious-groups-in-schoo  Nom  97%   0%   0%    11 /  3%     0 /  0%     2 
 7 anti-satellite-test-ban    Nom  97%   0%   0%    14 /  3%     0 /  0%     2 
 8 aid-to-nicaraguan-contras  Nom  97%   0%   0%    15 /  3%     0 /  0%     2 
 9 mx-missile                 Nom  95%   0%   0%    22 /  5%     0 /  0%     2 
10 immigration                Nom  98%   0%   0%     7 /  2%     0 /  0%     2 
11 synfuels-corporation-cutb  Nom  95%   0%   0%    21 /  5%     0 /  0%     2 
12 education-spending         Nom  93%   0%   0%    31 /  7%     0 /  0%     2 
13 superfund-right-to-sue     Nom  94%   0%   0%    25 /  6%     0 /  0%     2 
14 crime                      Nom  96%   0%   0%    17 /  4%     0 /  0%     2 
15 duty-free-exports          Nom  94%   0%   0%    28 /  6%     0 /  0%     2 
16 export-administration-act  Nom  76%   0%   0%   104 / 24%     0 /  0%     2 
17 Class                      Nom 100%   0%   0%     0 /  0%     0 /  0%     2 
```



#### Algo: OneR

**Results** :

|  | Precision | Recall | F-Measure |
| --- | --- | --- | --- |
| Training set : | 0.958 | 0.956 | 0.957 | 
| Cross-validation (10) : | 0.958 | 0.956 | 0.957 | 
| Leave one out (435) : | 0.958 | 0.956 | 0.957 | 
| Hold out (70%) : | 0.963 | 0.962 | 0.962 | 
**Comparaison** :

comparaison à l'aide du **F-Measure** :

le meilleur résultat est : Hold out (70%) 
la valeur qu'il a donné : 0.963

comparaison à l'aide du **Recall** :

le meilleur résultat est : Hold out (70%) 
la valeur qu'il a donné : 0.962

comparaison à l'aide du **Precision** :

le meilleur résultat est Hold out (70%) 
la valeur qu'il a donné : 0.962



#### Algo: NaiveBayes

**Results** :

|  | Precision | Recall | F-Measure |
| --- | --- | --- | --- |
| Training set : | 0.907 | 0.903 | 0.904 | 
| Cross-validation (10) : | 0.905 | 0.901 | 0.902 | 
| Leave one out (435) : | 0.905 | 0.901 | 0.902 | 
| Hold out (70%) : | 0.880 | 0.877 | 0.878 | 
**Comparaison** :

comparaison à l'aide du **F-Measure** :

le meilleur résultat est : Cross validation (10) 
la valeur qu'il a donné : 0.905

comparaison à l'aide du **Recall** :

le meilleur résultat est : Cross validation (10) 
la valeur qu'il a donné : 0.901

comparaison à l'aide du **Precision** :

le meilleur résultat est Cross validation (10) 
la valeur qu'il a donné : 0.902



#### Algo: IBk

**Results** :

|  | Precision | Recall | F-Measure |
| --- | --- | --- | --- |
| Training set : | 0.998 | 0.998 | 0.998 | 
| Cross-validation (10) : | 0.926 | 0.924 | 0.924 | 
| Leave one out (435) : | 0.926 | 0.924 | 0.925 | 
| Hold out (70%) : | 0.917 | 0.915 | 0.916 | 
**Comparaison** :

comparaison à l'aide du **F-Measure** :

le meilleur résultat est : Leave one out (435) 
la valeur qu'il a donné : 0.926

comparaison à l'aide du **Recall** :

le meilleur résultat est : Cross validation (10) 
la valeur qu'il a donné : 0.924

comparaison à l'aide du **Precision** :

le meilleur résultat est Leave one out (435) 
la valeur qu'il a donné : 0.925



#### Algo: J48

**Results** :

|  | Precision | Recall | F-Measure |
| --- | --- | --- | --- |
| Training set : | 0.972 | 0.972 | 0.972 | 
| Cross-validation (10) : | 0.965 | 0.966 | 0.965 | 
| Leave one out (435) : | 0.968 | 0.968 | 0.968 | 
| Hold out (70%) : | 0.969 | 0.969 | 0.969 | 
**Comparaison** :

comparaison à l'aide du **F-Measure** :

le meilleur résultat est : Hold out (70%) 
la valeur qu'il a donné : 0.969

comparaison à l'aide du **Recall** :

le meilleur résultat est : Hold out (70%) 
la valeur qu'il a donné : 0.969

comparaison à l'aide du **Precision** :

le meilleur résultat est Hold out (70%) 
la valeur qu'il a donné : 0.969



#### Algo: Id3

Une **erreur** s'est produite lors de l'évaluation

!>weka.classifiers.trees.Id3: Cannot handle missing values!

#### Comparaison entre algorithmes :

comparaison à l'aide du **F-Measure** :

le meilleur algorithme est : **J48** 

le meilleur résultat est : Hold out (70%) 
la valeur qu'il a donné : 0.969


comparaison à l'aide du **Recall** :

le meilleur algorithme est : **J48** 

le meilleur résultat est : Hold out (70%) 
la valeur qu'il a donné : 0.969


comparaison à l'aide du **Precision** :

le meilleur algorithme est : **J48** 

le meilleur résultat est Hold out (70%) 
la valeur qu'il a donné : 0.969


